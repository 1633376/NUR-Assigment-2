\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A plot of random number $x_{i+1}$ against random number $x_{i}$ for the first 1000 random uniforms produced by the random number generator. A good random number generator should produce a homogeneous plot without many (large) empty spots. In the above plot large empty spots appear to be absent, which suggests that the random number generator passes this test. }}{3}{figure.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The first 1000 random uniform numbers produced by the random number generator (RNG) against their index. A good random number generator should not have large wide gaps (e.g when moving from index 400 to 450 it should not only produce values larger than 0.8, which would leave a wide gap). In the plot these gaps appear to be absent. The average value produced by the RNG should furthermore be 0.5. This corresponds to rapidly moving up and down the line $ y = 0.5$. In the plot this should, result in a 'dense' region (less white) around the line $y = 0.5$. It can indeed be seen that the plot is denser close to $y = 0.5$ than at $y=0.8$ or $y=0.2$. }}{3}{figure.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The uniforms of the random number generator for 1 million random values. The values are binned in 20 bins. A good random number generator should fluctuate around 50000 $\pm 2\sqrt  {50000} = 50000 \pm 447 $ counts per bin (2 sigma). The maximum and minimum amount of counts corresponds to 50444 and 49642 counts. These value's just lay withing the 2 sigma uncertainty. The uniformness of the random number generator therefore appears to be quite acceptable. }}{4}{figure.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A histogram of the 1000 random nomal distributed variables generated with the box muller method for $\mu = 3$ and $\sigma = 2.4$ (orange) and the true normal distribution (red). The histogram approximates the normal distribution by eye, but displays some deviations. The peak is higher than it should be and slightly left of the peak is a bin with a low amount of counts. The left part of the histogram furthermore appears to be below the true normal distribution. By eye the histogram appears to be acceptable. A statistical test is of course better to determine whether the histogram would truly be acceptable or not.}}{6}{figure.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The P-value produced by the KS-test against the number of samples on which the KS-test is performed for the self written RNG. The red line indicates the line of $ p = 0.05$. A point \textbf  {below} thered line would suggests that there is enough statistical evidence to reject the (null) hypothesis that the data is normal distributed. The plot shows that the RNG always passes ks-test up to atleast $10^5$ samples.}}{9}{figure.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The P-value produced by the KS-test against the number of samples on which the KS-test is performed for the self written RNG. The red line indicates the line of $ p = 0.05$. The orange line is the self written implementation of the KS-test and the blue line is the scipy version. A point \textbf  {below} the red line would suggests that there is enough statistical evidence to reject the (null) hypothesis that the data is normal distributed. The self written ks-test is always close to the scipy version. It shows (small) deviations for small sample sizes. The exact cause of this is unknown, but is likely the result of an approximation that scipy makes that the self written implementation doesn't make (This is not confirmed by looking at the scipy code.). }}{9}{figure.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The P-value produced by the kuiper test against the number of samples on which the kuiper-test is performed for the self written RNG. The red line indicates the line of $ p = 0.05$. A point \textbf  {below} there line would suggests that there is enough statistical evidence to reject the (null) hypothesis that the data is normal distributed. The plot shows that the RNG always passes kuiper test. IT can however be seen that the value of the statistic stays lower for a significant amount of samples ($ N_{samples} > 10^4$). This might indicate that there is flaw in the random number generator.}}{11}{figure.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The P-value produced by the kuiper test against the number of samples on which the kuiper-test is performed for the self written RNG. The red line indicates the line of $ p = 0.05$. A point \textbf  {below} there line would suggests that there is enough statistical evidence to reject the (null) hypothesis that the data is normal distributed. The plot shows that the self written implementation deviates from the astropy implementation at the start, similar to what happend in the KS-test. }}{11}{figure.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The P-value produced by the kuiper test against the number of samples on which the kuiper-test is performed for the self written RNG. The red line indicates the line of $ p = 0.05$. A point \textbf  {below} there line would suggests that there is enough statistical evidence to reject the (null) hypothesis that the data is normal distributed. The plot shows that the RNG always passes kuiper test. IT can however be seen that the value of the statistic stays lower for a significant amount of samples ($ N_{samples} > 10^4$). This might indicate that there is flaw in the random number generator.}}{13}{figure.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The P-value produced by the kuiper test against the number of samples on which the kuiper-test is performed for the self written RNG. The red line indicates the line of $ p = 0.05$. A point \textbf  {below} there line would suggests that there is enough statistical evidence to reject the (null) hypothesis that the data is normal distributed. The plot shows that the self written implementation deviates from the astropy implementation at the start, similar to what happend in the KS-test. }}{13}{figure.10}}
